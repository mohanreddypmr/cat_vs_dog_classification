{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Data Preprocessing:"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":12,"outputs":[{"output_type":"stream","text":"/kaggle/input/dogs-vs-cats/sampleSubmission.csv\n/kaggle/input/dogs-vs-cats/test1.zip\n/kaggle/input/dogs-vs-cats/train.zip\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import zipfile\n\nwith zipfile.ZipFile(\"../input/dogs-vs-cats/train.zip\",\"r\") as z:\n    z.extractall(\".\")\n    \n    \nwith zipfile.ZipFile(\"../input/dogs-vs-cats/test1.zip\",\"r\") as z:\n    z.extractall(\".\")","execution_count":15,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_paths=os.listdir('/kaggle/working/train')","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_paths[:10]","execution_count":14,"outputs":[{"output_type":"execute_result","execution_count":14,"data":{"text/plain":"['cat.4951.jpg',\n 'cat.11829.jpg',\n 'cat.9873.jpg',\n 'cat.922.jpg',\n 'dog.1910.jpg',\n 'dog.871.jpg',\n 'dog.8385.jpg',\n 'dog.51.jpg',\n 'dog.8891.jpg',\n 'cat.8605.jpg']"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(train_paths)","execution_count":4,"outputs":[{"output_type":"execute_result","execution_count":4,"data":{"text/plain":"25000"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nos.mkdir('/kaggle/working/dogs')\nos.mkdir('/kaggle/working/cats')","execution_count":23,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from shutil import copyfile\nimport random\n\nfor i in train_paths:\n    if i.split('.')[0]=='dog':\n        source='/kaggle/working/train/'+i\n        destination='/kaggle/working/dogs/'+i\n        copyfile(source,destination)\n    else:\n        source='/kaggle/working/train/'+i\n        destination='/kaggle/working/cats/'+i\n        copyfile(source,destination)","execution_count":16,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(os.listdir('/kaggle/working/dogs/')))\nprint(len(os.listdir('/kaggle/working/cats/')))","execution_count":24,"outputs":[{"output_type":"stream","text":"12500\n12500\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"try:\n    os.mkdir('/kaggle/working/training')\n    os.mkdir('/kaggle/working/testing')\n    os.mkdir('/kaggle/working/training/cats')\n    os.mkdir('/kaggle/working/training/dogs')\n    os.mkdir('/kaggle/working/testing/cats')\n    os.mkdir('/kaggle/working/testing/dogs')\nexcept OSError:\n    print(123)\n    pass","execution_count":18,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def split_data(SOURCE, TRAINING, TESTING, SPLIT_SIZE):\n    files = []\n    for filename in os.listdir(SOURCE):\n        file = SOURCE + filename\n        if os.path.getsize(file) > 0:\n            files.append(filename)\n        else:\n            print(filename + \"is zero length\")\n\n    training_length = int(len(files) * SPLIT_SIZE)\n    testing_length = int(len(files) - training_length)\n    shuffled_set = random.sample(files, len(files))\n    training_set = shuffled_set[0:training_length]\n    testing_set = shuffled_set[-testing_length:]\n\n    for filename in training_set:\n        this_file = SOURCE + filename\n        destination = TRAINING + filename\n        copyfile(this_file, destination)\n\n    for filename in testing_set:\n        this_file = SOURCE + filename\n        destination = TESTING + filename\n        copyfile(this_file, destination)\n\n\n\nCAT_SOURCE_DIR = \"/kaggle/working/cats/\"\nTRAINING_CATS_DIR = \"/kaggle/working/training/cats/\"\nTESTING_CATS_DIR = \"/kaggle/working/testing/cats/\"\nDOG_SOURCE_DIR = \"/kaggle/working/dogs/\"\nTRAINING_DOGS_DIR = \"/kaggle/working/training/dogs/\"\nTESTING_DOGS_DIR = \"/kaggle/working/testing/dogs/\"\n\nsplit_size = .8\nsplit_data(CAT_SOURCE_DIR, TRAINING_CATS_DIR, TESTING_CATS_DIR, split_size)\nsplit_data(DOG_SOURCE_DIR, TRAINING_DOGS_DIR, TESTING_DOGS_DIR, split_size)","execution_count":19,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nTRAINING_DIR = \"/kaggle/working/training/\"\ntrain_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1.0/255)\ntrain_generator = train_datagen.flow_from_directory(TRAINING_DIR,\n                                                    batch_size=64,\n                                                    class_mode='binary',\n                                                    target_size=(224, 224))\n\nVALIDATION_DIR = \"/kaggle/working/testing/\"\nvalidation_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1.0/255)\nvalidation_generator = validation_datagen.flow_from_directory(VALIDATION_DIR,\n                                                              batch_size=64,\n                                                              class_mode='binary',\n                                                              target_size=(224, 224))","execution_count":26,"outputs":[{"output_type":"stream","text":"Found 20000 images belonging to 2 classes.\nFound 5000 images belonging to 2 classes.\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Architecture of Model using pretrained Vgg16:"},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.applications.vgg16 import VGG16\nfrom tensorflow import keras\nfrom tensorflow.keras.layers import Input\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\nfrom tensorflow.keras.layers import Conv2D, MaxPool2D \nImageFlow = tf.keras.preprocessing.image.ImageDataGenerator()\n \n\nmodel = VGG16(weights='imagenet',include_top=False,input_tensor=Input(shape=(224,224, 3)), classes=16)\nx = model.output\nx = Conv2D(filters=64,kernel_size=(3,3),strides=(1,1),padding='valid',data_format='channels_last',\n              activation='relu',kernel_initializer=tf.keras.initializers.he_normal(seed=0),name='Conv1')(x)\nx= MaxPool2D(pool_size=(2,2),strides=(2,2),padding='valid',data_format='channels_last',name='Pool1')(x)\nx= Flatten()(x)\nx = Dense(units=30,activation='relu',kernel_initializer=tf.keras.initializers.glorot_normal(seed=32),name='FC1')(x)\nx = Dense(units=15,activation='relu',kernel_initializer=tf.keras.initializers.glorot_normal(seed=33),name='FC2')(x)\nx = Dense(units=1,activation='sigmoid',kernel_initializer=tf.keras.initializers.glorot_normal(seed=3),name='Output')(x)\nfrom keras.models import Model\ncustom_model = Model(inputs=model.input, outputs=x)\nfor layer in model.layers[:19]:\n    layer.trainable = False\n\ncustom_model.summary()","execution_count":36,"outputs":[{"output_type":"stream","text":"Model: \"functional_5\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_6 (InputLayer)         [(None, 224, 224, 3)]     0         \n_________________________________________________________________\nblock1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n_________________________________________________________________\nblock1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n_________________________________________________________________\nblock1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n_________________________________________________________________\nblock2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n_________________________________________________________________\nblock2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n_________________________________________________________________\nblock2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n_________________________________________________________________\nblock3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n_________________________________________________________________\nblock3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n_________________________________________________________________\nblock3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n_________________________________________________________________\nblock3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n_________________________________________________________________\nblock4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n_________________________________________________________________\nblock4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n_________________________________________________________________\nblock4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n_________________________________________________________________\nblock4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n_________________________________________________________________\nblock5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n_________________________________________________________________\nblock5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n_________________________________________________________________\nblock5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n_________________________________________________________________\nblock5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n_________________________________________________________________\nConv1 (Conv2D)               (None, 5, 5, 64)          294976    \n_________________________________________________________________\nPool1 (MaxPooling2D)         (None, 2, 2, 64)          0         \n_________________________________________________________________\nflatten (Flatten)            (None, 256)               0         \n_________________________________________________________________\nFC1 (Dense)                  (None, 30)                7710      \n_________________________________________________________________\nFC2 (Dense)                  (None, 15)                465       \n_________________________________________________________________\nOutput (Dense)               (None, 1)                 16        \n=================================================================\nTotal params: 15,017,855\nTrainable params: 303,167\nNon-trainable params: 14,714,688\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Model_training:"},{"metadata":{"trusted":true},"cell_type":"code","source":"custom_model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['acc'])\ncustom_model.fit_generator(train_generator,validation_data=validation_generator,verbose=1,epochs=3)","execution_count":37,"outputs":[{"output_type":"stream","text":"Epoch 1/3\n313/313 [==============================] - 112s 357ms/step - loss: 0.2167 - acc: 0.9076 - val_loss: 0.1546 - val_acc: 0.9368\nEpoch 2/3\n313/313 [==============================] - 110s 351ms/step - loss: 0.1332 - acc: 0.9449 - val_loss: 0.1441 - val_acc: 0.9412\nEpoch 3/3\n313/313 [==============================] - 111s 353ms/step - loss: 0.0940 - acc: 0.9638 - val_loss: 0.1706 - val_acc: 0.9378\n","name":"stdout"},{"output_type":"execute_result","execution_count":37,"data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x7f1a40069110>"},"metadata":{}}]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}